{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import time\n",
        "import IPython.display as display"
      ],
      "metadata": {
        "id": "k69FwmgBSs87"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridWorldEnv:\n",
        "    def __init__(self, size=5, goals=None, obstacles=None):\n",
        "        self.size = size\n",
        "        self.action_space = ['up', 'down', 'left', 'right']\n",
        "\n",
        "        # Initialize goals\n",
        "        self.goals = []\n",
        "        if goals:\n",
        "            for g in goals:\n",
        "                self.goals.append({\n",
        "                    'pos_init': g['pos_init'],\n",
        "                    'pos': g['pos_init'],\n",
        "                    'moving': g.get('moving', False)\n",
        "                })\n",
        "\n",
        "        # Initialize obstacles\n",
        "        self.obstacles = []\n",
        "        if obstacles:\n",
        "            for o in obstacles:\n",
        "                self.obstacles.append({\n",
        "                    'pos_init': o['pos_init'],\n",
        "                    'pos': o['pos_init'],\n",
        "                    'moving': o.get('moving', False)\n",
        "                })\n",
        "\n",
        "        self.episode_count = 0  # Track episodes\n",
        "        self.reset()\n",
        "\n",
        "    def seed(self, seed_val):\n",
        "        random.seed(seed_val)\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = (0, 0)\n",
        "        self.done = False\n",
        "        self.episode_count += 1\n",
        "\n",
        "        # Reset obstacles to initial positions\n",
        "        for o in self.obstacles:\n",
        "            o['pos'] = o['pos_init']\n",
        "\n",
        "        # Reset or move goals\n",
        "        for g in self.goals:\n",
        "            if g['moving']:\n",
        "                g['pos'] = self._find_free_cell({self.agent_pos} | {o['pos'] for o in self.obstacles})\n",
        "            else:\n",
        "                g['pos'] = g['pos_init']\n",
        "\n",
        "        # Ensure no overlaps between all entities\n",
        "        self._resolve_conflicts()\n",
        "\n",
        "        return self.agent_pos\n",
        "\n",
        "    def _resolve_conflicts(self):\n",
        "        occupied = {self.agent_pos}\n",
        "\n",
        "        # Adjust goal positions if overlapping\n",
        "        for g in self.goals:\n",
        "            if g['pos'] in occupied:\n",
        "                g['pos'] = self._find_free_cell(occupied)\n",
        "            occupied.add(g['pos'])\n",
        "\n",
        "        # Adjust obstacle positions if overlapping\n",
        "        for o in self.obstacles:\n",
        "            if o['pos'] in occupied:\n",
        "                o['pos'] = self._find_free_cell(occupied)\n",
        "            occupied.add(o['pos'])\n",
        "\n",
        "    def _find_free_cell(self, occupied):\n",
        "        free = [(x, y) for x in range(self.size) for y in range(self.size)\n",
        "                if (x, y) not in occupied]\n",
        "        if not free:\n",
        "            raise Exception(\"No free cells left!\")\n",
        "        return random.choice(free)\n",
        "\n",
        "    def valid_position(self, pos, exclude_agent=True):\n",
        "        x, y = pos\n",
        "        if not (0 <= x < self.size and 0 <= y < self.size):\n",
        "            return False\n",
        "        if exclude_agent and pos == self.agent_pos:\n",
        "            return False\n",
        "        if any(g['pos'] == pos for g in self.goals):\n",
        "            return False\n",
        "        if any(o['pos'] == pos for o in self.obstacles):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def move_obstacles(self):\n",
        "        \"\"\"\n",
        "        Move obstacles randomly if they're marked as 'moving'.\n",
        "        \"\"\"\n",
        "        occupied = {self.agent_pos} | {g['pos'] for g in self.goals}\n",
        "        for o in self.obstacles:\n",
        "            occupied.discard(o['pos'])\n",
        "\n",
        "            if not o['moving']:\n",
        "                occupied.add(o['pos'])\n",
        "                continue\n",
        "\n",
        "            directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "            random.shuffle(directions)\n",
        "\n",
        "            for dx, dy in directions:\n",
        "                nx, ny = o['pos'][0] + dx, o['pos'][1] + dy\n",
        "                new_pos = (nx, ny)\n",
        "                if (0 <= nx < self.size and 0 <= ny < self.size and\n",
        "                        new_pos not in occupied):\n",
        "                    o['pos'] = new_pos\n",
        "                    break\n",
        "\n",
        "            occupied.add(o['pos'])\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Take a step in the environment.\n",
        "\n",
        "        Returns:\n",
        "            new_pos (tuple): New agent position\n",
        "            reward (int): Reward from the action\n",
        "            done (bool): Whether the episode is over\n",
        "            info (dict): Additional info (currently empty)\n",
        "        \"\"\"\n",
        "        if self.done:\n",
        "            return self.agent_pos, 0, True, {}\n",
        "\n",
        "        # Only obstacles move every step\n",
        "        self.move_obstacles()\n",
        "\n",
        "        # Compute new position\n",
        "        x, y = self.agent_pos\n",
        "        if action == 'up':\n",
        "            x = max(0, x - 1)\n",
        "        elif action == 'down':\n",
        "            x = min(self.size - 1, x + 1)\n",
        "        elif action == 'left':\n",
        "            y = max(0, y - 1)\n",
        "        elif action == 'right':\n",
        "            y = min(self.size - 1, y + 1)\n",
        "\n",
        "        new_pos = (x, y)\n",
        "\n",
        "        # Handle collisions and rewards\n",
        "        if any(o['pos'] == new_pos for o in self.obstacles):\n",
        "            reward = -10  # Hit obstacle\n",
        "            new_pos = self.agent_pos\n",
        "        elif any(g['pos'] == new_pos for g in self.goals):\n",
        "            reward = 30  # Reached goal\n",
        "            self.done = True\n",
        "        else:\n",
        "            reward = -0.1  # Step cost\n",
        "\n",
        "        self.agent_pos = new_pos\n",
        "        return self.agent_pos, reward, self.done, {}\n",
        "\n",
        "    def get_goal_positions(self):\n",
        "        return [g['pos'] for g in self.goals]\n",
        "\n",
        "    def get_obstacle_positions(self):\n",
        "        return [o['pos'] for o in self.obstacles]\n",
        "\n",
        "    def render(self):\n",
        "        grid = [['.' for _ in range(self.size)] for _ in range(self.size)]\n",
        "\n",
        "        for o in self.obstacles:\n",
        "            x, y = o['pos']\n",
        "            grid[x][y] = 'X'\n",
        "\n",
        "        for g in self.goals:\n",
        "            x, y = g['pos']\n",
        "            grid[x][y] = 'G'\n",
        "\n",
        "        ax, ay = self.agent_pos\n",
        "        grid[ax][ay] = 'A'\n",
        "\n",
        "        print(\"\\nGrid:\")\n",
        "        for row in grid:\n",
        "            print(\" \".join(row))\n",
        "        print()"
      ],
      "metadata": {
        "id": "z4CYKXdmQmzl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplorationNNAgent:\n",
        "    def __init__(self, learning_rate=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.action_size = 4  # up, down, left, right\n",
        "\n",
        "        # How often we explore vs use learned knowledge\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.1\n",
        "        self.epsilon_decay = 0.998\n",
        "        self.gamma = 0.95  # How much we value future rewards\n",
        "\n",
        "        # Memory to store past experiences for learning\n",
        "        self.memory = deque(maxlen=1000)\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Will build this once we know the state size\n",
        "        self.model = None\n",
        "\n",
        "    def build_model(self, state_size):\n",
        "        \"\"\"Create the neural network that will learn to make decisions\"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.model = models.Sequential([\n",
        "            layers.Dense(32, activation='relu', input_shape=(state_size,)),\n",
        "            layers.Dense(16, activation='relu'),\n",
        "            layers.Dense(self.action_size, activation='linear')\n",
        "        ])\n",
        "\n",
        "        self.model.compile(\n",
        "            loss='mse',\n",
        "            optimizer=optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        )\n",
        "        return self.model\n",
        "\n",
        "    def get_state_features(self, env):\n",
        "        \"\"\"Convert the environment into features the neural network can understand\"\"\"\n",
        "        agent_pos = env.agent_pos\n",
        "\n",
        "        features = []\n",
        "\n",
        "        # Where the agent is currently located (normalized)\n",
        "        features.extend([\n",
        "            agent_pos[0] / env.size,\n",
        "            agent_pos[1] / env.size\n",
        "        ])\n",
        "\n",
        "        # Check if there are obstacles in each direction\n",
        "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "        for dx, dy in directions:\n",
        "            check_pos = (agent_pos[0] + dx, agent_pos[1] + dy)\n",
        "            is_obstacle = any(check_pos == obs for obs in env.get_obstacle_positions())\n",
        "            features.append(1.0 if is_obstacle else 0.0)\n",
        "\n",
        "        # How close we are to walls\n",
        "        x, y = agent_pos\n",
        "        features.extend([\n",
        "            x / env.size,                    # Distance to top wall\n",
        "            (env.size - 1 - x) / env.size,   # Distance to bottom wall\n",
        "            y / env.size,                    # Distance to left wall\n",
        "            (env.size - 1 - y) / env.size    # Distance to right wall\n",
        "        ])\n",
        "\n",
        "        # Track if we've been here recently to encourage exploration\n",
        "        if hasattr(self, 'recent_positions'):\n",
        "            recent_visited = sum(1 for pos in self.recent_positions if pos == agent_pos)\n",
        "            features.append(min(recent_visited / 5.0, 1.0))\n",
        "        else:\n",
        "            features.append(0.0)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"Choose an action: sometimes explore randomly, sometimes use learned knowledge\"\"\"\n",
        "        if np.random.random() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "\n",
        "        state = np.array(state).reshape(1, -1)\n",
        "        q_values = self.model.predict(state, verbose=0)\n",
        "        return np.argmax(q_values[0])\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Save this experience for later learning\"\"\"\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "        # Keep track of where we've been recently\n",
        "        if not hasattr(self, 'recent_positions'):\n",
        "            self.recent_positions = deque(maxlen=10)\n",
        "        self.recent_positions.append(self._get_agent_position_from_state(state))\n",
        "\n",
        "    def _get_agent_position_from_state(self, state):\n",
        "        \"\"\"Figure out where the agent is from the state features\"\"\"\n",
        "        x = int(state[0] * self._env_size)\n",
        "        y = int(state[1] * self._env_size)\n",
        "        return (x, y)\n",
        "\n",
        "    def set_env_size(self, env_size):\n",
        "        \"\"\"Remember the environment size for converting positions\"\"\"\n",
        "        self._env_size = env_size\n",
        "\n",
        "    def replay(self):\n",
        "        \"\"\"Learn from past experiences\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        # Get a random sample of past experiences\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states = np.array([exp[0] for exp in batch])\n",
        "        actions = np.array([exp[1] for exp in batch])\n",
        "        rewards = np.array([exp[2] for exp in batch])\n",
        "        next_states = np.array([exp[3] for exp in batch])\n",
        "        dones = np.array([exp[4] for exp in batch])\n",
        "\n",
        "        # Predict what we think will happen\n",
        "        current_q = self.model.predict(states, verbose=0)\n",
        "        next_q = self.model.predict(next_states, verbose=0)\n",
        "\n",
        "        # Update our predictions based on what actually happened\n",
        "        target_q = current_q.copy()\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            if dones[i]:\n",
        "                target_q[i][actions[i]] = rewards[i]\n",
        "            else:\n",
        "                target_q[i][actions[i]] = rewards[i] + self.gamma * np.max(next_q[i])\n",
        "\n",
        "        # Train the neural network with our improved predictions\n",
        "        self.model.fit(states, target_q, epochs=1, verbose=0, batch_size=self.batch_size)\n",
        "\n",
        "        # Gradually do less exploring and more using learned knowledge\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "class ExplorationTrainer:\n",
        "    def __init__(self, env, episodes=500, max_steps=100):\n",
        "        self.env = env\n",
        "        self.episodes = episodes\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "        # Create our learning agent\n",
        "        self.agent = ExplorationNNAgent()\n",
        "\n",
        "        # Figure out how many features our state has\n",
        "        sample_features = self.agent.get_state_features(self.env)\n",
        "        state_size = len(sample_features)\n",
        "        print(f\"Detected state size: {state_size}\")\n",
        "\n",
        "        # Build the neural network with the correct size\n",
        "        self.agent.build_model(state_size)\n",
        "        self.agent.set_env_size(env.size)\n",
        "\n",
        "        # Track how well we're doing\n",
        "        self.rewards_all_episodes = []\n",
        "        self.steps_all_episodes = []\n",
        "        self.success_rate = []\n",
        "        self.exploration_rates = []\n",
        "\n",
        "        # Keep track of where we've been\n",
        "        self.visited_cells = set()\n",
        "\n",
        "    def _get_exploration_bonus(self, position):\n",
        "        \"\"\"Give rewards for exploring new places\"\"\"\n",
        "        if position not in self.visited_cells:\n",
        "            self.visited_cells.add(position)\n",
        "            return 0.5  # Good job finding someplace new!\n",
        "        return -0.05   # Small penalty for going where we've already been\n",
        "\n",
        "    def train(self):\n",
        "        print(\"Starting Exploration Training\")\n",
        "        print(\"The agent doesn't know where the goal is - it has to search the whole grid!\")\n",
        "\n",
        "        successes = 0\n",
        "\n",
        "        for episode in range(1, self.episodes + 1):\n",
        "            state = self.env.reset()\n",
        "            state_features = self.agent.get_state_features(self.env)\n",
        "            total_reward = 0\n",
        "            episode_visited = set()\n",
        "\n",
        "            # Reset visited cells for this episode\n",
        "            self.visited_cells = set()\n",
        "\n",
        "            for step in range(self.max_steps):\n",
        "                prev_position = self.env.agent_pos\n",
        "\n",
        "                # Choose what to do\n",
        "                action_idx = self.agent.act(state_features)\n",
        "                action = self.env.action_space[action_idx]\n",
        "\n",
        "                # Do it and see what happens\n",
        "                next_state, env_reward, done, _ = self.env.step(action)\n",
        "                next_state_features = self.agent.get_state_features(self.env)\n",
        "                current_position = self.env.agent_pos\n",
        "\n",
        "                # Calculate rewards for exploration\n",
        "                exploration_bonus = self._get_exploration_bonus(current_position)\n",
        "                episode_visited.add(current_position)\n",
        "\n",
        "                # Small reward for actually moving\n",
        "                movement_reward = 0.0\n",
        "                if current_position != prev_position:\n",
        "                    movement_reward = 0.1\n",
        "\n",
        "                # Combine all the rewards\n",
        "                total_step_reward = env_reward + exploration_bonus + movement_reward\n",
        "\n",
        "                # Big penalty for hitting obstacles\n",
        "                if env_reward == -10:\n",
        "                    total_step_reward = -5\n",
        "\n",
        "                # Remember this experience\n",
        "                self.agent.remember(state_features, action_idx, total_step_reward,\n",
        "                                  next_state_features, done)\n",
        "\n",
        "                # Start learning after we have some experiences\n",
        "                if episode > 10:\n",
        "                    self.agent.replay()\n",
        "\n",
        "                # Update our state\n",
        "                state_features = next_state_features\n",
        "                total_reward += total_step_reward\n",
        "\n",
        "                if done:\n",
        "                    if env_reward == 30:  # Found the goal!\n",
        "                        successes += 1\n",
        "                        total_reward += 10  # Extra reward for success\n",
        "                    break\n",
        "\n",
        "            # Record how we did\n",
        "            self.rewards_all_episodes.append(total_reward)\n",
        "            self.steps_all_episodes.append(step + 1)\n",
        "            self.success_rate.append(successes / episode)\n",
        "            self.exploration_rates.append(self.agent.epsilon)\n",
        "\n",
        "            # Show progress every so often\n",
        "            if episode % 50 == 0:\n",
        "                coverage = len(episode_visited) / (self.env.size ** 2)\n",
        "                recent_success = np.mean(self.success_rate[-50:]) if episode >= 50 else self.success_rate[-1]\n",
        "                avg_reward = np.mean(self.rewards_all_episodes[-50:]) if episode >= 50 else self.rewards_all_episodes[-1]\n",
        "\n",
        "                print(f\"Episode {episode}:\")\n",
        "                print(f\"   Success Rate: {recent_success:.2%}\")\n",
        "                print(f\"   Coverage: {coverage:.2%}\")\n",
        "                print(f\"   Avg Reward: {avg_reward:.2f}\")\n",
        "                print(f\"   Exploration: {self.agent.epsilon:.3f}\")\n",
        "                print(f\"   Steps: {step + 1}\")\n",
        "                print(\"-\" * 40)\n",
        "\n",
        "        return {\n",
        "            'env': self.env,\n",
        "            'agent': self.agent,\n",
        "            'rewards': self.rewards_all_episodes,\n",
        "            'steps': self.steps_all_episodes,\n",
        "            'success_rate': self.success_rate,\n",
        "            'exploration_rates': self.exploration_rates\n",
        "        }\n",
        "\n",
        "class ExplorationAnimator:\n",
        "    def __init__(self, env, agent):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.visited_positions = set()\n",
        "\n",
        "    def render_exploration(self, step, action, reward, total_reward):\n",
        "        \"\"\"Create a visualization of what the agent is doing and where it has been\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Create a grid to represent the current state\n",
        "        grid = np.zeros((self.env.size, self.env.size))\n",
        "\n",
        "        # Mark obstacles\n",
        "        for obs in self.env.get_obstacle_positions():\n",
        "            grid[obs[0], obs[1]] = -1\n",
        "\n",
        "        # Mark goals\n",
        "        for goal in self.env.get_goal_positions():\n",
        "            grid[goal[0], goal[1]] = 2\n",
        "\n",
        "        # Mark where the agent is\n",
        "        agent_pos = self.env.agent_pos\n",
        "        grid[agent_pos[0], agent_pos[1]] = 1\n",
        "\n",
        "        # Remember we've been here\n",
        "        self.visited_positions.add(agent_pos)\n",
        "\n",
        "        # Left plot: Current situation\n",
        "        im1 = ax1.imshow(grid, cmap='RdYlBu', vmin=-1, vmax=2)\n",
        "        ax1.set_title(f'Current State\\nStep: {step} | Action: {action}')\n",
        "        ax1.grid(True, color='black', linewidth=0.5)\n",
        "\n",
        "        # Right plot: Where we've been\n",
        "        exploration_grid = np.zeros((self.env.size, self.env.size))\n",
        "        for pos in self.visited_positions:\n",
        "            exploration_grid[pos[0], pos[1]] = 1\n",
        "\n",
        "        im2 = ax2.imshow(exploration_grid, cmap='Greens', vmin=0, vmax=1)\n",
        "        ax2.set_title(f'Exploration Map\\nVisited: {len(self.visited_positions)}/{self.env.size**2} cells')\n",
        "        ax2.grid(True, color='black', linewidth=0.5)\n",
        "\n",
        "        # Add overall information\n",
        "        fig.suptitle(f'Reward: {reward} | Total: {total_reward:.1f} | Epsilon: {self.agent.epsilon:.3f}',\n",
        "                    fontsize=14, y=0.95)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # FIXED: Use the correct method for getting the image from matplotlib\n",
        "        fig.canvas.draw()\n",
        "\n",
        "        # Get the RGB buffer from the figure\n",
        "        buf = fig.canvas.buffer_rgba()\n",
        "        image = np.asarray(buf)\n",
        "\n",
        "        # Convert RGBA to RGB\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "        plt.close(fig)\n",
        "        return image\n",
        "\n",
        "    def animate(self, episodes=2, max_steps=50, delay=0.5):\n",
        "        \"\"\"Show the agent exploring in real-time\"\"\"\n",
        "        for episode in range(episodes):\n",
        "            state = self.env.reset()\n",
        "            state_features = self.agent.get_state_features(self.env)\n",
        "            total_reward = 0\n",
        "            self.visited_positions = set()\n",
        "\n",
        "            print(f\"Exploration Episode {episode + 1}\")\n",
        "            print(\"The agent is searching for the goal without knowing where it is\")\n",
        "\n",
        "            for step in range(max_steps):\n",
        "                # Choose an action using current policy\n",
        "                action_idx = self.agent.act(state_features)\n",
        "                action = self.env.action_space[action_idx]\n",
        "\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                next_state_features = self.agent.get_state_features(self.env)\n",
        "\n",
        "                total_reward += reward\n",
        "\n",
        "                # Show what's happening\n",
        "                frame = self.render_exploration(step + 1, action, reward, total_reward)\n",
        "                display.clear_output(wait=True)\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                plt.imshow(frame)\n",
        "                plt.axis('off')\n",
        "                plt.title(f'Exploration - Episode {episode + 1}, Step {step + 1}')\n",
        "                plt.show()\n",
        "\n",
        "                print(f\"Step {step + 1}: {action} | Reward: {reward:6.1f} | Total: {total_reward:6.1f}\")\n",
        "                print(f\"Position: {self.env.agent_pos} | Visited: {len(self.visited_positions)} cells\")\n",
        "\n",
        "                if done:\n",
        "                    if reward == 30:\n",
        "                        print(\"SUCCESS! Found the goal through exploration!\")\n",
        "                    else:\n",
        "                        print(\"Hit obstacle!\")\n",
        "                    break\n",
        "\n",
        "                state_features = next_state_features\n",
        "                time.sleep(delay)\n",
        "\n",
        "            if not done:\n",
        "                print(\"Timeout - didn't find goal this episode\")\n",
        "\n",
        "            print(f\"Final coverage: {len(self.visited_positions)}/{self.env.size**2} cells\")\n",
        "\n",
        "            if episode < episodes - 1:\n",
        "                print(\"=\"*50)\n",
        "                input(\"Press Enter for next episode...\")\n",
        "\n",
        "def plot_exploration_results(results):\n",
        "    \"\"\"Create plots to show how the learning progressed\"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # How rewards improved over time\n",
        "    moving_avg = np.convolve(results['rewards'], np.ones(20)/20, mode='valid')\n",
        "    ax1.plot(moving_avg, linewidth=2)\n",
        "    ax1.set_title('Learning Curve (Moving Avg Reward)')\n",
        "    ax1.set_xlabel('Episode')\n",
        "    ax1.set_ylabel('Average Reward')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # How often we succeeded\n",
        "    ax2.plot(results['success_rate'], linewidth=2, color='green')\n",
        "    ax2.set_title('Success Rate Over Time')\n",
        "    ax2.set_xlabel('Episode')\n",
        "    ax2.set_ylabel('Success Rate')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # How exploration changed over time\n",
        "    ax3.plot(results['exploration_rates'], linewidth=2, color='orange')\n",
        "    ax3.set_title('Exploration Rate (Epsilon)')\n",
        "    ax3.set_xlabel('Episode')\n",
        "    ax3.set_ylabel('Epsilon')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # How many steps we took\n",
        "    moving_steps = np.convolve(results['steps'], np.ones(20)/20, mode='valid')\n",
        "    ax4.plot(moving_steps, linewidth=2, color='red')\n",
        "    ax4.set_title('Steps per Episode (Moving Avg)')\n",
        "    ax4.set_xlabel('Episode')\n",
        "    ax4.set_ylabel('Steps')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary of final performance\n",
        "    final_success = np.mean(results['success_rate'][-50:]) if len(results['success_rate']) >= 50 else results['success_rate'][-1]\n",
        "    final_reward = np.mean(results['rewards'][-50:]) if len(results['rewards']) >= 50 else results['rewards'][-1]\n",
        "    print(\"FINAL PERFORMANCE (last 50 episodes):\")\n",
        "    print(f\"   Success Rate: {final_success:.2%}\")\n",
        "    print(f\"   Average Reward: {final_reward:.2f}\")\n",
        "    print(f\"   Final Exploration Rate: {results['agent'].epsilon:.3f}\")"
      ],
      "metadata": {
        "id": "A-zY-OeEyso8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Use a smaller grid so learning doesn't take forever\n",
        "    GRID_SIZE = 5\n",
        "    EPISODES = 100\n",
        "\n",
        "    print(\"EXPLORATION TRAINING MODE\")\n",
        "    print(\"The agent has NO idea where the goal is!\")\n",
        "    print(\"It has to learn to explore efficiently to find it randomly!\")\n",
        "\n",
        "    # Create the environment\n",
        "    # Note: You'll need to have the GridWorldEnv class defined or imported\n",
        "    env = GridWorldEnv(\n",
        "        size=GRID_SIZE,\n",
        "        goals=[{'pos_init': (GRID_SIZE-1, GRID_SIZE-1), 'moving': False}],\n",
        "        obstacles=[\n",
        "            {'pos_init': (1, 1), 'moving': False},\n",
        "            {'pos_init': (2, 3), 'moving': False},\n",
        "            {'pos_init': (3, 1), 'moving': False}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Train the agent\n",
        "    trainer = ExplorationTrainer(env, episodes=EPISODES, max_steps=100)\n",
        "    results = trainer.train()\n",
        "\n",
        "    # Show what the agent learned\n",
        "    print(\"Animating Learned Exploration Behavior...\")\n",
        "    animator = ExplorationAnimator(results['env'], results['agent'])\n",
        "    animator.animate(episodes=3, max_steps=40, delay=0.3)\n",
        "\n",
        "    # Plot the results\n",
        "    plot_exploration_results(results)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "bzkPMxuq0WpH",
        "outputId": "f1145f09-9885-418c-b96b-047ea9a83c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 9: right | Reward:   30.0 | Total:   19.3\n",
            "Position: (4, 4) | Visited: 8 cells\n",
            "SUCCESS! Found the goal through exploration!\n",
            "Final coverage: 8/25 cells\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}